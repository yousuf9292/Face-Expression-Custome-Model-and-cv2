{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"C:\\\\Users\\\\yousuf\\\\Desktop\\\\fer2013\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fer2013.bib', 'fer2013.csv', 'README', 'train', 'validation']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path=dir+'\\\\validation\\\\'\n",
    "train_path=dir+'\\\\train\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim1=[]\n",
    "dim2=[]\n",
    "\n",
    "for filename in os.listdir(test_path+'Angry'):\n",
    "    img=plt.imread(test_path+'Angry\\\\'+filename)\n",
    "    d1,d2=img.shape\n",
    "    dim1.append(d1)\n",
    "    dim2.append(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagee=os.listdir(test_path+'\\\\Angry')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen=ImageDataGenerator(rotation_range=0.1,zoom_range=0.1,width_shift_range=0.1,height_shift_range=0.1,horizontal_flip=True,\n",
    "                          fill_mode='nearest',shear_range=0.1,rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=cv2.imread('C:\\\\Users\\\\yousuf\\\\Desktop\\\\fer2013\\\\validation\\\\Angry\\\\10.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22020303608>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_gen.random_transform(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape=(224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Dropout,Conv2D,MaxPool2D,BatchNormalization\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(64,(3,3),input_shape=(img_shape),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Conv2D(128,(3,3),input_shape=(img_shape),activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Conv2D(256,(3,3),input_shape=(img_shape),activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(256,(3,3),input_shape=(img_shape),activation='relu',padding='same'))\n",
    "model.add(MaxPool2D((2,2),padding='same'))\n",
    "model.add(Conv2D(512,(3,3),input_shape=(img_shape),activation='relu',padding='same'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(6,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 46, 46, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 46, 46, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 2, 2, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 2,240,390\n",
      "Trainable params: 2,240,262\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28272 images belonging to 6 classes.\n",
      "Found 3534 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_img_gen=img_gen.flow_from_directory(train_path,target_size=img_shape[:2],batch_size=batch_size,class_mode='categorical',color_mode='grayscale')\n",
    "test_img_gen=img_gen.flow_from_directory(test_path,target_size=img_shape[:2],batch_size=batch_size,class_mode='categorical',shuffle=False,color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_gen.image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "early=EarlyStopping(monitor='val_loss',patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1767/1767 [==============================] - 492s 279ms/step - loss: 1.7202 - accuracy: 0.2649 - val_loss: 1.2721 - val_accuracy: 0.2306\n",
      "Epoch 2/100\n",
      "1767/1767 [==============================] - 365s 206ms/step - loss: 1.5364 - accuracy: 0.3705 - val_loss: 0.9472 - val_accuracy: 0.3868\n",
      "Epoch 3/100\n",
      "1767/1767 [==============================] - 363s 205ms/step - loss: 1.4062 - accuracy: 0.4430 - val_loss: 0.9200 - val_accuracy: 0.4318\n",
      "Epoch 4/100\n",
      "1767/1767 [==============================] - 367s 208ms/step - loss: 1.3352 - accuracy: 0.4708 - val_loss: 1.2373 - val_accuracy: 0.4403\n",
      "Epoch 5/100\n",
      "1767/1767 [==============================] - 367s 208ms/step - loss: 1.2832 - accuracy: 0.4937 - val_loss: 0.9877 - val_accuracy: 0.4618\n",
      "Epoch 6/100\n",
      "1767/1767 [==============================] - 367s 208ms/step - loss: 1.2477 - accuracy: 0.5088 - val_loss: 0.9812 - val_accuracy: 0.4844\n",
      "Epoch 7/100\n",
      "1767/1767 [==============================] - 367s 208ms/step - loss: 1.2217 - accuracy: 0.5230 - val_loss: 1.0989 - val_accuracy: 0.4827\n",
      "Epoch 8/100\n",
      "1767/1767 [==============================] - 366s 207ms/step - loss: 1.1902 - accuracy: 0.5352 - val_loss: 0.8821 - val_accuracy: 0.4952\n",
      "Epoch 9/100\n",
      " 411/1767 [=====>........................] - ETA: 4:33 - loss: 1.1762 - accuracy: 0.5427"
     ]
    }
   ],
   "source": [
    "results=model.fit_generator(train_img_gen,epochs=100,validation_data=test_img_gen,callbacks=[early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict_generator(test_img_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "for i in range(len(prediction)):\n",
    "    labels.append(np.argmax(prediction[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_img_gen.classes,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(test_img_gen.classes,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('face.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('face.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 46, 46, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 21, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 2, 2, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 1,669,063\n",
      "Trainable params: 1,669,063\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0215362310409546, 0.4895513951778412]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_img_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "image=cv2.imread('C:\\\\Users\\\\yousuf\\\\Desktop\\\\fer2013\\\\validation\\\\Surprise\\\\8.jpg',1)\n",
    "expanded_image=np.expand_dims(image,axis=0)\n",
    "predict=model.predict_classes(expanded_image)\n",
    "print(predict)\n",
    "cv2.imshow('Image',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Angry': 0,\n",
       " 'Disgust': 1,\n",
       " 'Fear': 2,\n",
       " 'Happy': 3,\n",
       " 'Neutral': 4,\n",
       " 'Sad': 5,\n",
       " 'Surprise': 6}"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img_gen.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using The Model with CV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "model=load_model('face.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 46, 46, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 21, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 2, 2, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 1,669,063\n",
      "Trainable params: 1,669,063\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "font=cv2.FONT_HERSHEY_COMPLEX\n",
    "face_cascade=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "while True:\n",
    "    _,frame=cap.read()\n",
    "    \n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces=face_cascade.detectMultiScale(gray,1.3,5)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        roi=frame[y:y+h,x:x+w]\n",
    "    \n",
    "        resiezed=cv2.resize(frame,(48,48))\n",
    "        \n",
    "        expanded_img=np.expand_dims(resiezed,axis=0)\n",
    "        \n",
    "        prediction=model.predict_classes(expanded_img)\n",
    "        \n",
    "\n",
    "        if prediction==0:\n",
    "            cv2.putText(frame,\"Angry\",(1,20),font,1,(0,0,255),2,cv2.LINE_AA)\n",
    "        if prediction==1:\n",
    "            cv2.putText(frame,\"Disgust\",(1,20),font,1,(0,0,255),2,cv2.LINE_AA)\n",
    "        if prediction==2:\n",
    "            cv2.putText(frame,\"Fear\",(1,20),font,1,(0,0,255),2,cv2.LINE_AA)\n",
    "        if prediction==3:\n",
    "            cv2.putText(frame,\"Happy\",(1,20),font,1,(0,0,255),2,cv2.LINE_AA)\n",
    "        if prediction==4:\n",
    "            cv2.putText(frame,\"Neutral\",(1,20),font,1,(0,0,255),2,cv2.LINE_AA)\n",
    "        if prediction==5:\n",
    "            cv2.putText(frame,\"Sad\",(1,20),font,1,(0,0,255),2,cv2.LINE_AA)\n",
    "        if prediction==6:\n",
    "            cv2.putText(frame,\"Surprise\",(1,20),font,1,(0,0,255),2,cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('frame',frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF== ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
